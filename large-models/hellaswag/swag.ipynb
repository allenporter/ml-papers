{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will start with the SWAG dataset to get a baseline before moving on to the HellaSwag dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from datasets import load_dataset\n",
    "\n",
    "with patch(\"datasets.builder.is_remote_filesystem\", return_value=False):\n",
    "    dataset = load_dataset(\"swag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sample(question='Members of the procession walk down the street holding small horn brass instruments. A drum line', answers=['passes by walking down the street playing their instruments.', 'has heard approaching them.', \"arrives and they're outside dancing and asleep.\", 'turns the lead singer watches the performance.'], label=0),\n",
       " Sample(question='A drum line passes by walking down the street playing their instruments. Members of the procession', answers=['are playing ping pong and celebrating one left each in quick.', 'wait slowly towards the cadets.', 'continues to play as well along the crowd along with the band being interviewed.', 'continue to play marching, interspersed.'], label=3),\n",
       " Sample(question='A group of members in green uniforms walks waving flags. Members of the procession', answers=['pay the other coaches to cheer as people this chatter dips in lawn sheets.', 'walk down the street holding small horn brass instruments.', 'is seen in the background.', 'are talking a couple of people playing a game of tug of war.'], label=1))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "NUM_ANSWERS = 4\n",
    "CHOICES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sample:\n",
    "    \"\"\"A sample multiple choice question.\"\"\"\n",
    "\n",
    "    question: str\n",
    "    answers: list[str]\n",
    "    label: int\n",
    "\n",
    "    @property\n",
    "    def choices(self) -> list[str]:\n",
    "        \"\"\"Return the multiple choice answers.\"\"\"\n",
    "        return [ f\"{choice}) {option}\" for choice, option in zip(CHOICES, self.answers) ]\n",
    "\n",
    "    @property\n",
    "    def label_text(self) -> str:\n",
    "        \"\"\"Returns the expected correct answer.\"\"\"\n",
    "        return self.answers[self.label]\n",
    "\n",
    "    @property\n",
    "    def expected(self) -> str:\n",
    "        \"\"\"Returns the expected correct answer.\"\"\"\n",
    "        return f\"{CHOICES[self.label]}) {self.label_text}\"\n",
    "\n",
    "\n",
    "def make_sample(record: dict[str, str]) -> Sample:\n",
    "    return Sample(record[\"startphrase\"], [record[f\"ending{i}\"] for i in range(0, NUM_ANSWERS)], label=record[\"label\"])\n",
    "\n",
    "ds = dataset['train']\n",
    "it = iter(ds)\n",
    "make_sample(next(it)), make_sample(next(it)), make_sample(next(it))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Client\n",
    "\n",
    "This will open a client library to talk to a local model server hosting the model we wish to eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital city of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "BASE_URL = \"http://llama-cpp-server.llama:8000/v1\"\n",
    "API_KEY = \"sk-xxx\"\n",
    "MODEL_ID = \"/data/models/mistral-7b-inst.gguf\"\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "            \"role\": \"system\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"What is the capital of France?\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sample(question='A drum line passes by walking down the street playing their instruments. Members of the procession', answers=['are playing ping pong and celebrating one left each in quick.', 'wait slowly towards the cadets.', 'makes a square call and ends by jumping down into snowy streets where fans begin to take their positions.', 'play and go back and forth hitting the drums while the audience claps for them.'], label=3),\n",
       " 'The most plausible continuation for the story would be D) Play and go back and forth hitting the drums while the audience claps for them.')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSTRUCTIONS = \"Choose the most plausible continuation for the story.\"\n",
    "HEADER = \"Please answer with the letter of the correct answer.\"\n",
    "\n",
    "\n",
    "def multiple_choice_prompt(sample: Sample) -> str:\n",
    "    \"\"\"Make a prompt from a sample.\"\"\"\n",
    "    return \"\\n\".join([\n",
    "        HEADER,\n",
    "        \"\",\n",
    "        sample.question,\n",
    "        \"\",\n",
    "        *sample.choices\n",
    "    ])\n",
    "\n",
    "\n",
    "def answer(client: OpenAI, sample: Sample) -> str:\n",
    "    prompt = multiple_choice_prompt(sample)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=[\n",
    "            {\n",
    "                \"content\": INSTRUCTIONS,\n",
    "                \"role\": \"system\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": prompt,\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "    return choice.message.content.strip()\n",
    "\n",
    "\n",
    "sample = make_sample(next(it))\n",
    "response = answer(client, sample)\n",
    "sample, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "it = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00% - 0 of 1: : 1it [00:16, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) continues to play as well along the crowd along with the band being interviewed.\n",
      "D) continue to play marching, interspersed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60.00% - 3 of 5: : 5it [01:07, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without additional context or information about the story, it is difficult to determine the most plausible continuation. Therefore, all of the options (A, B, C, and D) could be possible continuations depending on the context. Could you please provide more information or details about the story so that I can better assist you?\n",
      "D) turns on a monitor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 3 of 6: : 6it [01:22, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) rush for the unconscious mother.\n",
      "D) turned to look at someone as he approaches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 4 of 8: : 8it [01:47, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story is D) rolls up his fast run from the water and tosses in the sky.\n",
      "C) falls to the ground.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44.44% - 4 of 9: : 9it [02:00, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) lights his walking stick as he aims his pistol at someone's wand.\n",
      "B) leans back to her surroundings, his eyes rimmed with tears.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 6 of 12: : 12it [02:30, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) stops the little boy inside.\n",
      "C) looks up at him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.15% - 6 of 13: : 13it [02:45, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without any context or further information, it is difficult to determine which continuation is the most plausible. Please provide more details or clues about the story so I can assist you better.\n",
      "A) pull a wall down on top of him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.67% - 7 of 15: : 15it [03:08, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story is: A) wheels behind his back as the troll sprays to the top of the tower.\n",
      "B) smashes through a pane of glass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55.00% - 11 of 20: : 20it [04:05, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) jumps again and forces his eyes upward.\n",
      "C) is kicked away by someone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54.55% - 12 of 22: : 22it [04:31, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<</SYS>> The most plausible continuation for the story is: D) is open into a web.\n",
      "B) crashes through the wall of an old ruin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54.17% - 13 of 24: : 24it [04:58, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<</SYS>> I'm sorry, but could you please provide me with more context or information about the story? This will help me provide a more accurate and plausible continuation for the story.\n",
      "B) pushes it back, then hurls someone across the ruin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.14% - 16 of 28: : 28it [05:46, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct answer is B) moves in slow motion.\n",
      "C) is then shown again again in slow motion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55.17% - 16 of 29: : 29it [05:57, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) climbs down the rock as she goes.\n",
      "C) is then shown doing the same action in slow motion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53.33% - 16 of 30: : 30it [06:07, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) is shown walking and twirling herself on a gym hoop while judges watch.\n",
      "D) appears in front of the camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51.61% - 16 of 31: : 31it [06:23, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) stop as someone draws beside someone and lands in the limo's trunk.\n",
      "D) someone and someone push one suv down a hill, leaving a man turn over to the traffic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 16 of 32: : 32it [06:32, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) turn into the Burnham Driveway.\n",
      "B) turn into the burnham driveway.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.48% - 16 of 33: : 33it [06:48, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story is option D: \"pulls up a little and goes to help someone up.\"\n",
      "B) is sprawled on the couch in his underwear, drinking a beer and controlling the car.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.06% - 16 of 34: : 34it [07:02, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) in purple is wearing a blue dress and blue headband, using the pits to style her hair.\n",
      "C) talks to the camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.65% - 18 of 37: : 37it [07:30, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) continues drying the man's hair.\n",
      "C) continues showing various hair products at camera afterwards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.37% - 18 of 38: : 38it [07:39, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct answer is B) swing out from under the twisted wall.\n",
      "D) upset some piled newspapers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.50% - 19 of 40: : 40it [08:05, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without additional context or information about the story, it is not possible for me to determine which continuation is the most plausible. Can you please provide more details about what happens next in the story?\n",
      "C) pushes someone to the ground, and goes to his gate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.62% - 20 of 42: : 42it [08:43, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct continuation of the story is:\n",
      "\n",
      "B) continues moving along the set.\n",
      "A) clap his hands over the instrument as the others speak into the microphone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.51% - 20 of 43: : 43it [08:51, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) play a song together themselves and sings.\n",
      "B) continue to play together in separate frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.67% - 21 of 45: : 45it [09:14, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) are moving back and forth in the grass.\n",
      "C) are all riding bumper cars around a track.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.92% - 23 of 48: : 48it [09:53, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) looks up and finds someone in a sunlit tower.\n",
      "B) pours him a drink.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.00% - 24 of 50: : 50it [10:20, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story is C) \"pulls over and rushes out to the zebra observing him.\"\n",
      "B) skates up to him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.06% - 24 of 51: : 51it [10:32, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) folds paper ribbon for me and then puts it in the cellophane.\n",
      "B) moves the cat off the table and onto the floor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.15% - 24 of 52: : 52it [10:45, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<</SYS>> B) hits the nail up while the timer captures her around.\n",
      "C) adds more tissue paper to the bag.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45.28% - 24 of 53: : 53it [10:54, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) The correct answer is B.\n",
      "A) see an intro screen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44.44% - 24 of 54: : 54it [11:02, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) see a score board.\n",
      "B) see the girl puts gifts into a gift bag with tissue paper.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43.64% - 24 of 55: : 55it [11:13, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) rinses his hands on the soap.\n",
      "B) takes a yellow rag and cleans the sink and faucet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.54% - 29 of 61: : 61it [12:26, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story would be:\n",
      "\n",
      "A) dances and then talks around.\n",
      "B) cleans a contact lens in the palm of his hand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.44% - 31 of 64: : 64it [13:02, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) continue to routine at the end while the audience cheers.\n",
      "D) continue spinning and dancing all around the room and ends with them stopping and facing the camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47.69% - 31 of 65: : 65it [13:16, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct answer is C: They take off most of their headgear and start walking back together.\n",
      "C) take of most of their head gear and start walking back together.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.97% - 31 of 66: : 66it [13:32, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<</SYS>> The most plausible continuation for the story would be option (C).\n",
      "D) is seen again with wet hair and closes his eyes to the camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.27% - 31 of 67: : 67it [13:43, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) begins to move, dropping the object down, then beginning to jump horizontal.\n",
      "D) uses the pole to hit a pinata over and over.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.38% - 32 of 69: : 69it [14:09, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without additional context, it is difficult to determine the most plausible continuation for the story. However, based solely on the given information, the most likely continuation would be:\n",
      "\n",
      "B) is holding a harmonica in the sky.\n",
      "A) is standing talking to the camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45.71% - 32 of 70: : 70it [14:23, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story would be: \n",
      "\n",
      "A) walks a little more than a while.\n",
      "B) stops and demonstrates how to sharpen the knife as he talks to a camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46.58% - 34 of 73: : 73it [14:59, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) walks up to someone, who's wearing the necklace in someone's uniform, followed by someone.\n",
      "B) goes over to his desk, to his right, holding his hand down.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48.00% - 36 of 75: : 75it [15:29, 12.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, record \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     sample \u001b[39m=\u001b[39m make_sample(\u001b[39mnext\u001b[39m(it))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     response \u001b[39m=\u001b[39m answer(client, sample)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Sometimes the model may answer something like 'The best answer is A) <answer>'\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# so we'll give it credit.\u001b[39;00m\n",
      "\u001b[1;32m/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer\u001b[39m(client: OpenAI, sample: Sample) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     prompt \u001b[39m=\u001b[39m multiple_choice_prompt(sample)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         model\u001b[39m=\u001b[39;49mMODEL_ID,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m             {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: INSTRUCTIONS,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m             },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m             {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m             }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         ],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     choice \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-papers-client.devpod/workspaces/ml-papers-client/ml-papers/large-models/hellaswag/swag.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m choice\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_utils/_utils.py:303\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    601\u001b[0m             {\n\u001b[1;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    620\u001b[0m             },\n\u001b[1;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    622\u001b[0m         ),\n\u001b[1;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    629\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1086\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1073\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1074\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1082\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1083\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1084\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1085\u001b[0m     )\n\u001b[0;32m-> 1086\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:846\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    838\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    839\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    844\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    845\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    847\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    848\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    849\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    850\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    851\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    852\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:872\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    869\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 872\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    873\u001b[0m         request,\n\u001b[1;32m    874\u001b[0m         auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth,\n\u001b[1;32m    875\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    876\u001b[0m     )\n\u001b[1;32m    877\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    878\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[1;32m    879\u001b[0m     )\n\u001b[1;32m    880\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    233\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    234\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    235\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    236\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(it))\n",
    "for i, record in pbar:\n",
    "    sample = make_sample(next(it))\n",
    "    response = answer(client, sample)\n",
    "    total += 1\n",
    "    # Sometimes the model may answer something like 'The best answer is A) <answer>'\n",
    "    # so we'll give it credit.\n",
    "    if response == sample.expected or sample.label_text in response:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(response)\n",
    "        print(sample.expected)\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    pbar.set_description(f\"{accuracy:2.2f}% - {correct} of {total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
