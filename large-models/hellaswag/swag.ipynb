{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will start with the SWAG dataset to get a baseline before moving on to the HellaSwag dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from datasets import load_dataset\n",
    "\n",
    "with patch(\"datasets.builder.is_remote_filesystem\", return_value=False):\n",
    "    dataset = load_dataset(\"swag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sample(question='Members of the procession walk down the street holding small horn brass instruments. A drum line', answers=['passes by walking down the street playing their instruments.', 'has heard approaching them.', \"arrives and they're outside dancing and asleep.\", 'turns the lead singer watches the performance.'], label=0),\n",
       " Sample(question='A drum line passes by walking down the street playing their instruments. Members of the procession', answers=['are playing ping pong and celebrating one left each in quick.', 'wait slowly towards the cadets.', 'continues to play as well along the crowd along with the band being interviewed.', 'continue to play marching, interspersed.'], label=3),\n",
       " Sample(question='A group of members in green uniforms walks waving flags. Members of the procession', answers=['pay the other coaches to cheer as people this chatter dips in lawn sheets.', 'walk down the street holding small horn brass instruments.', 'is seen in the background.', 'are talking a couple of people playing a game of tug of war.'], label=1))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "NUM_ANSWERS = 4\n",
    "CHOICES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sample:\n",
    "    \"\"\"A sample multiple choice question.\"\"\"\n",
    "\n",
    "    question: str\n",
    "    answers: list[str]\n",
    "    label: int\n",
    "\n",
    "    @property\n",
    "    def choices(self) -> list[str]:\n",
    "        \"\"\"Return the multiple choice answers.\"\"\"\n",
    "        return [ f\"{choice}) {option}\" for choice, option in zip(CHOICES, self.answers) ]\n",
    "\n",
    "    @property\n",
    "    def label_text(self) -> str:\n",
    "        \"\"\"Returns the expected correct answer.\"\"\"\n",
    "        return self.answers[self.label]\n",
    "\n",
    "    @property\n",
    "    def expected(self) -> str:\n",
    "        \"\"\"Returns the expected correct answer.\"\"\"\n",
    "        return f\"{CHOICES[self.label]}) {self.label_text}\"\n",
    "\n",
    "\n",
    "def make_sample(record: dict[str, str]) -> Sample:\n",
    "    return Sample(record[\"startphrase\"], [record[f\"ending{i}\"] for i in range(0, NUM_ANSWERS)], label=record[\"label\"])\n",
    "\n",
    "ds = dataset['train']\n",
    "it = iter(ds)\n",
    "make_sample(next(it)), make_sample(next(it)), make_sample(next(it))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Client\n",
    "\n",
    "This will open a client library to talk to a local model server hosting the model we wish to eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital city of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "BASE_URL = \"http://llama-cpp-server.llama:8000/v1\"\n",
    "API_KEY = \"sk-xxx\"\n",
    "MODEL_ID = \"/data/models/mistral-7b-inst.gguf\"\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "            \"role\": \"system\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"What is the capital of France?\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sample(question='A drum line passes by walking down the street playing their instruments. Members of the procession', answers=['are playing ping pong and celebrating one left each in quick.', 'wait slowly towards the cadets.', 'makes a square call and ends by jumping down into snowy streets where fans begin to take their positions.', 'play and go back and forth hitting the drums while the audience claps for them.'], label=3),\n",
       " 'The most plausible continuation for the story would be D) Play and go back and forth hitting the drums while the audience claps for them.')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSTRUCTIONS = \"Choose the most plausible continuation for the story.\"\n",
    "HEADER = \"Please answer with the letter of the correct answer.\"\n",
    "\n",
    "\n",
    "def multiple_choice_prompt(sample: Sample) -> str:\n",
    "    \"\"\"Make a prompt from a sample.\"\"\"\n",
    "    return \"\\n\".join([\n",
    "        HEADER,\n",
    "        \"\",\n",
    "        sample.question,\n",
    "        \"\",\n",
    "        *sample.choices\n",
    "    ])\n",
    "\n",
    "\n",
    "def answer(client: OpenAI, sample: Sample) -> str:\n",
    "    prompt = multiple_choice_prompt(sample)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=[\n",
    "            {\n",
    "                \"content\": INSTRUCTIONS,\n",
    "                \"role\": \"system\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": prompt,\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "    return choice.message.content.strip()\n",
    "\n",
    "\n",
    "sample = make_sample(next(it))\n",
    "response = answer(client, sample)\n",
    "sample, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "it = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00% - 0 of 1: : 1it [00:16, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) continues to play as well along the crowd along with the band being interviewed.\n",
      "D) continue to play marching, interspersed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60.00% - 3 of 5: : 5it [01:07, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without additional context or information about the story, it is difficult to determine the most plausible continuation. Therefore, all of the options (A, B, C, and D) could be possible continuations depending on the context. Could you please provide more information or details about the story so that I can better assist you?\n",
      "D) turns on a monitor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 3 of 6: : 6it [01:22, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) rush for the unconscious mother.\n",
      "D) turned to look at someone as he approaches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 4 of 8: : 8it [01:47, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most plausible continuation for the story is D) rolls up his fast run from the water and tosses in the sky.\n",
      "C) falls to the ground.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44.44% - 4 of 9: : 9it [02:00, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) lights his walking stick as he aims his pistol at someone's wand.\n",
      "B) leans back to her surroundings, his eyes rimmed with tears.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.00% - 6 of 12: : 12it [02:30, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D) stops the little boy inside.\n",
      "C) looks up at him.\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(it))\n",
    "for i, record in pbar:\n",
    "    sample = make_sample(next(it))\n",
    "    response = answer(client, sample)\n",
    "    total += 1\n",
    "    # Sometimes the model may answer something like 'The best answer is A) <answer>'\n",
    "    # so we'll give it credit.\n",
    "    if response == sample.expected or sample.label_text in response:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(response)\n",
    "        print(sample.expected)\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    pbar.set_description(f\"{accuracy:2.2f}% - {correct} of {total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
