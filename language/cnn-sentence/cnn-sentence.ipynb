{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU.\n",
      "Vocab size: 20251, 59\n",
      "Num reviews: 8530 / 8530\n",
      "Vocab sample: [('<pad>', 0), ('<unk>', 1), ('the', 2), ('rock', 3), ('is', 4), ('destined', 5), ('to', 6), ('be', 7), ('21st', 8), (\"century's\", 9), ('new', 10), ('\"', 11), ('conan', 12), ('and', 13), ('that', 14)]\n",
      "Vocab inv sample: [(0, '<pad>'), (1, '<unk>'), (2, 'the'), (3, 'rock'), (4, 'is'), (5, 'destined'), (6, 'to'), (7, 'be'), (8, '21st'), (9, \"century's\"), (10, 'new'), (11, '\"'), (12, 'conan'), (13, 'and'), (14, 'that')]\n",
      "tensor([ 2,  3,  4,  5,  6,  7,  2,  8,  9, 10, 11, 12, 11, 13, 14, 15, 16,  6,\n",
      "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0])\n",
      "tensor([0., 1.])\n",
      "tensor([ 5339,   156,   532,  3593,    25,   365,   253,  1850,  3542,   170,\n",
      "            2,    78,     4,    95, 18963,    13,   109,  5660,    32,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import itertools\n",
    "import torch\n",
    "from typing import Any\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"Using mps backend\")\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using cuda backend\")\n",
    "        print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "        return torch.device(\"cuda\")\n",
    "    print('No GPU available, using the CPU.')\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()  # torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def tokenize(sentence: str) -> list[str]:\n",
    "    \"\"\"Tokenize the sentence into words.\"\"\"\n",
    "    return sentence.lower().split(' ')\n",
    "\n",
    "\n",
    "MAX_SENTENCE_LEN = 60  # Assumes only first N elements are allowed\n",
    "PAD = '<pad>'\n",
    "PAD_IDX = 0\n",
    "UNK = '<unk>'\n",
    "UNK_IDX = 1\n",
    "START_IDX = 2\n",
    "\n",
    "def build_vocab(contents: list[str]) -> dict[str, int]:\n",
    "    \"\"\"Build an index of words to token number.\"\"\"\n",
    "    vocab: dict[str, int] = {}\n",
    "    vocab[PAD] = PAD_IDX\n",
    "    vocab[UNK] = UNK_IDX\n",
    "    index = START_IDX\n",
    "    max_words = 0\n",
    "    for line in contents:\n",
    "        tokens = tokenize(line)\n",
    "        max_words = max(len(tokens), max_words)\n",
    "        for word in itertools.islice(tokens, MAX_SENTENCE_LEN):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = index\n",
    "                index += 1\n",
    "    return vocab, max_words\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "labels1 = [ item['text'] for item in dataset['train']]\n",
    "labels2 = [ item['text'] for item in dataset['validation']]\n",
    "vocab, max_words = build_vocab(labels1 + labels2)\n",
    "vocab_inv = { v: k for k, v in vocab.items()}\n",
    "\n",
    "\n",
    "# From the paper: The input is a concatenated sentence (length n) where each word is\n",
    "# represented as a k-dimensional word vector. X[i, i+j] = concat(Xi, Xi+1, ..., Xi+j)\n",
    "# The sentence is padded where necessary.\n",
    "\n",
    "def encode_sentence(sentence: str) -> list[int]:\n",
    "    \"\"\"Encode a sentence as a series of token indexes.\"\"\"\n",
    "    encoded = [ vocab.get(word.lower(), UNK_IDX) for word in itertools.islice(tokenize(sentence), MAX_SENTENCE_LEN) ]\n",
    "    if len(encoded) < MAX_SENTENCE_LEN:\n",
    "        encoded.extend([PAD_IDX] * (MAX_SENTENCE_LEN - len(encoded)))\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def build_tensors(dataset: DatasetDict) -> (torch.tensor, torch.tensor):\n",
    "    encoded_reviews: list[list[int]] = []\n",
    "    labels: list[tuple[float]] = []\n",
    "    for item in dataset:\n",
    "        encoded_reviews.append(encode_sentence(item['text']))\n",
    "        if item['label'] == 1:\n",
    "            labels.append((0.0, 1.0))\n",
    "        else:\n",
    "            labels.append((1.0, 0.0))\n",
    "    review_inputs = torch.tensor(encoded_reviews)\n",
    "    review_labels = torch.tensor(labels)\n",
    "    return review_inputs, review_labels\n",
    "\n",
    "\n",
    "encoded_reviews: list[list[int]] = []\n",
    "labels: list[tuple[float]] = []\n",
    "for item in dataset['train']:\n",
    "    encoded_reviews.append(encode_sentence(item['text']))\n",
    "    if item['label'] == 1:\n",
    "        labels.append((0.0, 1.0))\n",
    "    else:\n",
    "        labels.append((1.0, 0.0))\n",
    "Xtr, Ytr = build_tensors(dataset['train'])\n",
    "Xdev, Ydev = build_tensors(dataset['validation'])\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, {max_words}\")\n",
    "print(f\"Num reviews: {len(Xtr)} / {len(Ytr)}\")\n",
    "print(f\"Vocab sample: {list(vocab.items())[0:15]}\")\n",
    "print(f\"Vocab inv sample: {list(vocab_inv.items())[0:15]}\")\n",
    "print(review_inputs[0])\n",
    "print(review_labels[0])\n",
    "print(review_inputs[-1])\n",
    "print(review_labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 79589    0 79589    0     0  53272      0 --:--:--  0:00:01 --:--:-- 53272\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20251/20251 [00:00<00:00, 442171.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20251 20251 15181\n",
      "torch.Size([20251, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "WORD2VEC = 'data/GoogleNews-vectors-negative300.bin'\n",
    "MAX_WORDLEN = 50\n",
    "WEIGHT_SIZE = 4\n",
    "EMBED_DIM = 300  # Embedding size\n",
    "\n",
    "\n",
    "def load_word2vec(vocab: dict[str, int]) -> torch.tensor:\n",
    "    # Could be improved matching distribution of word2vec\n",
    "    vocab_vec = numpy.random.uniform(-0.25, 0.25, (len(vocab), EMBED_DIM))\n",
    "    vocab_vec[PAD_IDX] = numpy.zeros(EMBED_DIM)\n",
    "    found: set[int] = set()\n",
    "    with open(WORD2VEC, 'rb') as fd:\n",
    "        line = fd.readline()\n",
    "        parts = line.decode('utf-8').split(' ')\n",
    "        words = int(parts[0])\n",
    "        word_size = int(parts[1])\n",
    "        if word_size != EMBED_DIM:\n",
    "            raise ValueError(f\"Unexpected word size {word_size} != {EMBED_DIM}\")\n",
    "        for i in tqdm(range(0, words)):\n",
    "            # Read the next word\n",
    "            s = b''\n",
    "            while True:\n",
    "                ch = fd.read(1)\n",
    "                if ch == b' ':\n",
    "                    break\n",
    "                if ch == b'':\n",
    "                    raise ValueError(\"Unexpected eof\")\n",
    "                if ch != b'\\n':\n",
    "                    s += ch\n",
    "                if len(s) > word_size:\n",
    "                    raise ValueError(f\"Word was too long {s}\")\n",
    "            weights = fd.read(word_size * WEIGHT_SIZE)\n",
    "            wd = numpy.frombuffer(weights, dtype=numpy.float32)\n",
    "            word = s.decode('utf-8').strip().lower()\n",
    "            # Only load words in the vocabulary\n",
    "            if (idx := vocab.get(word)) is not None:\n",
    "                if idx not in found:\n",
    "                    vocab_vec[idx] = wd\n",
    "                    found |= set({idx})\n",
    "\n",
    "    return torch.tensor(vocab_vec)\n",
    "\n",
    "\n",
    "w2v_model = models.KeyedVectors.load_word2vec_format(WORD2VEC, binary=True)\n",
    "\n",
    "\n",
    "def encode_word2vec(vocab: dict[str, int]) -> torch.tensor:\n",
    "    # Could be improved matching distribution of word2vec\n",
    "    vocab_vec = numpy.random.uniform(-0.25, 0.25, (len(vocab), EMBED_DIM))\n",
    "    vocab_vec[PAD_IDX] = numpy.zeros(EMBED_DIM)\n",
    "    found = 0\n",
    "    for word, idx in tqdm(vocab.items()):\n",
    "        if word in w2v_model:\n",
    "            vocab_vec[idx] = w2v_model[word]\n",
    "            found += 1\n",
    "    return torch.tensor(vocab_vec, dtype=torch.float64), found\n",
    "\n",
    "vocab2vec, found = encode_word2vec(vocab)\n",
    "print(len(vocab), len(vocab2vec), found)\n",
    "print(vocab2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([-0.0679, -0.1194,  0.1216, -0.1063, -0.1108,  0.0274, -0.0921,  0.1946,\n",
      "        -0.2059,  0.2495], dtype=torch.float64)\n",
      "tensor([ 0.0801,  0.1050,  0.0498,  0.0535, -0.0674, -0.1206,  0.0352, -0.1187,\n",
      "         0.0439,  0.0302], dtype=torch.float64)\n",
      "\n",
      "vocab['car']\n",
      "6485\n",
      "vocab2vec['car']\n",
      "6485\n",
      "tensor([ 0.2441, -0.1070,  0.1057,  0.1528, -0.0175,  0.0547,  0.0686, -0.1089,\n",
      "        -0.1635, -0.1677], dtype=torch.float64)\n",
      "w2v_model['car']\n",
      "[ 0.13085938  0.00842285  0.03344727 -0.05883789  0.04003906 -0.14257812\n",
      "  0.04931641 -0.16894531  0.20898438  0.11962891]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "print(vocab2vec[0][:10])\n",
    "print(vocab2vec[1][:10])\n",
    "print(vocab2vec[2][:10])\n",
    "print()\n",
    "print(\"vocab['car']\")\n",
    "print(vocab['car'])\n",
    "print(\"vocab2vec['car']\")\n",
    "print(vocab['car'])\n",
    "print(vocab2vec[6514][:10])\n",
    "print(\"w2v_model['car']\")\n",
    "print(w2v_model['car'][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "FILTER_WINDOWS = (3, 4, 5)\n",
    "FEATURE_MAPS = 200\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"A model for training a CNN text classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddings: torch.tensor, rand_embed: bool, freeze_embedding: bool, num_classes: int, dropout: float = 0.5):\n",
    "        \"\"\"Initialize Model.\"\"\"\n",
    "        super().__init__()\n",
    "        if not rand_embed:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=freeze_embedding).float()\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=vocab2vec.shape[0],\n",
    "                embedding_dim=vocab2vec.shape[1],\n",
    "                padding_idx=0,\n",
    "                max_norm=5.0\n",
    "            )\n",
    "        self.conv_list = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=EMBED_DIM,\n",
    "                out_channels=FEATURE_MAPS,\n",
    "                kernel_size=filter_size,\n",
    "            )\n",
    "            for filter_size in FILTER_WINDOWS\n",
    "        ])\n",
    "        self.fc = nn.Linear(FEATURE_MAPS * len(FILTER_WINDOWS), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Out: (BATCH_SZ, MAX_SENTENCE_LEN, WORD_SIZE)\n",
    "        self.x_embed = self.embedding(x)\n",
    "        # Reshape to match conv1d input\n",
    "        # Out: (BATCH_SZ, WORD_SIZE, MAX_SENTENCE_LEN)\n",
    "        self.x_reshape = self.x_embed.permute(0, 2, 1) \n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-2)\n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-3)\n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-4)\n",
    "        self.x_conv_list = [F.relu(conv(self.x_reshape)) for conv in self.conv_list]\n",
    "        # (BATCH_SZ, FEATURE_MAPS, 1)\n",
    "        self.x_pool_list = [\n",
    "            F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in self.x_conv_list\n",
    "        ]\n",
    "        # (BATCH_SZ, FEATURE_MAPS * 3)\n",
    "        self.x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in self.x_pool_list], dim=1)\n",
    "        # (BATCH_SZ, FEATURE_MAPS * 3)\n",
    "        self.logits = self.fc(self.dropout(self.x_fc))\n",
    "        self.logits_class = F.softmax(self.logits, dim=1)\n",
    "        return self.logits_class\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/ml-papers/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:597: UserWarning: pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  | 4.26i/s | 0.688 | 0.679 | 68.37 |  15.73  /  0.43  \n",
      " 1  | 5.45i/s | 0.667 | 0.659 | 64.14 |  12.29  /  0.45  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m         accuracy \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mround(logits) \u001b[39m==\u001b[39m Yb)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mmean() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m     41\u001b[0m         accuracyi\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[0;32m---> 43\u001b[0m         opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     45\u001b[0m avg_train_loss \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mmean(lossi)\n\u001b[1;32m     46\u001b[0m iters \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lossi)\n",
      "File \u001b[0;32m~/ml-papers/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/ml-papers/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/ml-papers/venv/lib/python3.11/site-packages/torch/optim/adadelta.py:108\u001b[0m, in \u001b[0;36mAdadelta.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m     lr, rho, eps, weight_decay, foreach, maximize, differentiable \u001b[39m=\u001b[39m (\n\u001b[1;32m     97\u001b[0m         group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     98\u001b[0m         group[\u001b[39m\"\u001b[39m\u001b[39mrho\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m         group[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(group, params_with_grad, grads, square_avgs, acc_deltas)\n\u001b[0;32m--> 108\u001b[0m     adadelta(\n\u001b[1;32m    109\u001b[0m         params_with_grad,\n\u001b[1;32m    110\u001b[0m         grads,\n\u001b[1;32m    111\u001b[0m         square_avgs,\n\u001b[1;32m    112\u001b[0m         acc_deltas,\n\u001b[1;32m    113\u001b[0m         lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    114\u001b[0m         rho\u001b[39m=\u001b[39;49mrho,\n\u001b[1;32m    115\u001b[0m         eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    116\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    117\u001b[0m         foreach\u001b[39m=\u001b[39;49mforeach,\n\u001b[1;32m    118\u001b[0m         maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    119\u001b[0m         differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/ml-papers/venv/lib/python3.11/site-packages/torch/optim/adadelta.py:206\u001b[0m, in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, foreach, differentiable, lr, rho, eps, weight_decay, maximize)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adadelta\n\u001b[0;32m--> 206\u001b[0m func(\n\u001b[1;32m    207\u001b[0m     params,\n\u001b[1;32m    208\u001b[0m     grads,\n\u001b[1;32m    209\u001b[0m     square_avgs,\n\u001b[1;32m    210\u001b[0m     acc_deltas,\n\u001b[1;32m    211\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    212\u001b[0m     rho\u001b[39m=\u001b[39;49mrho,\n\u001b[1;32m    213\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    214\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    215\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    216\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m~/ml-papers/venv/lib/python3.11/site-packages/torch/optim/adadelta.py:249\u001b[0m, in \u001b[0;36m_single_tensor_adadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay, maximize, differentiable)\u001b[0m\n\u001b[1;32m    247\u001b[0m square_avg\u001b[39m.\u001b[39mmul_(rho)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m rho)\n\u001b[1;32m    248\u001b[0m std \u001b[39m=\u001b[39m square_avg\u001b[39m.\u001b[39madd(eps)\u001b[39m.\u001b[39msqrt_()\n\u001b[0;32m--> 249\u001b[0m delta \u001b[39m=\u001b[39m acc_delta\u001b[39m.\u001b[39;49madd(eps)\u001b[39m.\u001b[39msqrt_()\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m differentiable:\n\u001b[1;32m    251\u001b[0m     delta \u001b[39m=\u001b[39m delta\u001b[39m.\u001b[39mclone()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "\n",
    "MINI_BATCH_SZ = 128\n",
    "\n",
    "g = torch.Generator(device=device).manual_seed(31337)\n",
    "g_cpu = torch.Generator().manual_seed(31337)\n",
    "pin_memory = True if device.type != 'cpu' else False\n",
    "\n",
    "tr_data = TensorDataset(Xtr, Ytr)\n",
    "tr_loader = DataLoader(tr_data, sampler=RandomSampler(tr_data, generator=g_cpu), batch_size=MINI_BATCH_SZ, pin_memory=pin_memory, pin_memory_device=device.type)\n",
    "\n",
    "val_data = TensorDataset(Xdev, Ydev)\n",
    "val_loader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=MINI_BATCH_SZ, pin_memory=pin_memory, pin_memory_device=device.type)\n",
    "\n",
    "model = Model(embeddings=vocab2vec, rand_embed=False, freeze_embedding=False, num_classes=2, dropout=0.5)\n",
    "\n",
    "lr = 0.25\n",
    "opt = torch.optim.Adadelta(model.parameters(), lr=lr, rho=0.95)\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    lossi = []\n",
    "    accuracyi = []\n",
    "    t0_epoch = time.time()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for step, batch in enumerate(tr_loader):\n",
    "            Xb, Yb = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "            logits = model.forward(Xb)\n",
    "            loss = F.cross_entropy(logits, Yb)\n",
    "            loss.backward()\n",
    "\n",
    "            lossi.append(loss.item())\n",
    "            accuracy = (torch.round(logits) == Yb).cpu().numpy().mean() * 100\n",
    "            accuracyi.append(accuracy)\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "    avg_train_loss = numpy.mean(lossi)\n",
    "    iters = len(lossi)\n",
    "    time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "    t0_epoch = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lossi = []\n",
    "        accuracyi = []\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            Xb, Yb = tuple(t.to(device) for t in batch)\n",
    "            logits = model.forward(Xb)\n",
    "            loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "            lossi.append(loss.item())\n",
    "            accuracy = (torch.round(logits) == Yb).cpu().numpy().mean() * 100\n",
    "            accuracyi.append(accuracy)\n",
    "\n",
    "        avg_eval_loss = numpy.mean(lossi)\n",
    "        avg_eval_accuracy = numpy.mean(accuracyi)\n",
    "\n",
    "    eval_time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "    print(f\"{epoch:^3} | {iters/time_elapsed:3.2f}i/s | {avg_train_loss:0.3f} | {avg_eval_loss:0.3f} | {avg_eval_accuracy:0.2f} | {time_elapsed:^7.2f} / {eval_time_elapsed:^7.2f}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This review is 69.52% positive.\n",
      "This review is 73.19% positive.\n",
      "This review is 98.76% positive.\n",
      "This review is 9.61% positive.\n",
      "This review is 54.91% positive.\n",
      "---\n",
      "This review is 0.01% positive.\n",
      "This review is 9.06% positive.\n",
      "This review is 0.42% positive.\n",
      "This review is 4.02% positive.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "def predict(text: str) -> None:\n",
    "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
    "    text = text.replace(\",\", \" ,\")\n",
    "    text = text.replace(\".\", \" .\").lower()\n",
    "    #print(text)\n",
    "    encoded = torch.tensor(encode_sentence(text), device=device)\n",
    "    input_data = encoded.unsqueeze(dim=0)\n",
    "\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(input_data)\n",
    "\n",
    "    # Compute probability\n",
    "    prob = logits.squeeze(dim=0)\n",
    "    print(f\"This review is {prob[1] * 100:.2f}% positive.\")\n",
    "\n",
    "\n",
    "predict(\"All of friends slept while watching this movie, but I really enjoyed it.\")\n",
    "predict(\"I have waited so long for this movie and I am now so satisfied and happy.\")\n",
    "predict(\"This is a great movie.\")\n",
    "predict(\"I was laughing the whole time.\")\n",
    "predict(\"Fantastic movie that I would watch again.\")\n",
    "print(\"---\")\n",
    "predict(\"This movie is long and boring.\")\n",
    "predict(\"I don't like the ending.\")\n",
    "predict(\"Do not bother watching this movie.\")\n",
    "predict(\"I hated this movie more than any other movie.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
