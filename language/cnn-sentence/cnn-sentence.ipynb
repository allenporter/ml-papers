{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda backend\n",
      "There are 1 GPU(s) available.\n",
      "Vocab size: 21619, 61\n",
      "Num reviews: 10662 / 10662\n",
      "Vocab sample: [('<pad>', 0), ('<unk>', 1), ('the', 2), ('rock', 3), ('is', 4), ('destined', 5), ('to', 6), ('be', 7), ('21st', 8), (\"century's\", 9), ('new', 10), ('\"', 11), ('conan', 12), ('and', 13), ('that', 14)]\n",
      "Vocab inv sample: [(0, '<pad>'), (1, '<unk>'), (2, 'the'), (3, 'rock'), (4, 'is'), (5, 'destined'), (6, 'to'), (7, 'be'), (8, '21st'), (9, \"century's\"), (10, 'new'), (11, '\"'), (12, 'conan'), (13, 'and'), (14, 'that')]\n",
      "tensor([ 2,  3,  4,  5,  6,  7,  2,  8,  9, 10, 11, 12, 11, 13, 14, 15, 16,  6,\n",
      "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0])\n",
      "tensor([0., 1.])\n",
      "tensor([12681,     4,  1473,    25,    58,   132,   653,   700,  2838,    13,\n",
      "          700,  9113,    32,    33,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import itertools\n",
    "import torch\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "MOVIE_REVIEW_DIR = pathlib.Path('data/movie_reviews/txt_sentoken/')\n",
    "\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"Using mps backend\")\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using cuda backend\")\n",
    "        print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "        return torch.device(\"cuda\")\n",
    "    print('No GPU available, using the CPU.')\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()  # torch.device(\"cpu\")\n",
    "\n",
    "def load_reviews(path: pathlib.Path, glob: str) -> list[str]:\n",
    "    \"\"\"Build movie review training set from the dataset directory\"\"\"\n",
    "    x = []\n",
    "    for filename in path.glob(glob):\n",
    "        with filename.open() as f:\n",
    "            x.extend(f.readlines())\n",
    "    return x\n",
    "\n",
    "def tokenize(sentence: str) -> list[str]:\n",
    "    \"\"\"Tokenize the sentence into words.\"\"\"\n",
    "    return sentence.lower().split(' ')\n",
    "\n",
    "\n",
    "MAX_SENTENCE_LEN = 60  # Assumes only first N elements are allowed\n",
    "PAD = '<pad>'\n",
    "PAD_IDX = 0\n",
    "UNK = '<unk>'\n",
    "UNK_IDX = 1\n",
    "START_IDX = 2\n",
    "\n",
    "def build_vocab(contents: list[str]) -> dict[str, int]:\n",
    "    \"\"\"Build an index of words to token number.\"\"\"\n",
    "    vocab: dict[str, int] = {}\n",
    "    vocab[PAD] = PAD_IDX\n",
    "    vocab[UNK] = UNK_IDX\n",
    "    index = START_IDX\n",
    "    max_words = 0\n",
    "    for line in contents:\n",
    "        tokens = tokenize(line)\n",
    "        max_words = max(len(tokens), max_words)\n",
    "        for word in itertools.islice(tokens, MAX_SENTENCE_LEN):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = index\n",
    "                index += 1\n",
    "    return vocab, max_words\n",
    "\n",
    "POS = load_reviews(MOVIE_REVIEW_DIR, \"rt-polarity.pos\")\n",
    "NEG = load_reviews(MOVIE_REVIEW_DIR, \"rt-polarity.neg\")\n",
    "#POS = load_reviews(MOVIE_REVIEW_DIR / \"pos\", glob=\"*.txt\")\n",
    "#NEG = load_reviews(MOVIE_REVIEW_DIR / \"neg\", glob=\"*.txt\")\n",
    "\n",
    "vocab, max_words = build_vocab(POS + NEG)\n",
    "vocab_inv = { v: k for k, v in vocab.items()}\n",
    "\n",
    "# From the paper: The input is a concatenated sentence (length n) where each word is\n",
    "# represented as a k-dimensional word vector. X[i, i+j] = concat(Xi, Xi+1, ..., Xi+j)\n",
    "# The sentence is padded where necessary.\n",
    "\n",
    "def encode_sentence(sentence: str) -> list[int]:\n",
    "    \"\"\"Encode a sentence as a series of token indexes.\"\"\"\n",
    "    encoded = [ vocab.get(word.lower(), UNK_IDX) for word in itertools.islice(tokenize(sentence), MAX_SENTENCE_LEN) ]\n",
    "    if len(encoded) < MAX_SENTENCE_LEN:\n",
    "        encoded.extend([PAD_IDX] * (MAX_SENTENCE_LEN - len(encoded)))\n",
    "    return encoded\n",
    "\n",
    "\n",
    "encoded_reviews: list[list[int]] = []\n",
    "labels: list[tuple[float]] = []\n",
    "for review in POS:\n",
    "    encoded_reviews.append(encode_sentence(review))\n",
    "    labels.append((0.0, 1.0))\n",
    "for review in NEG:\n",
    "    encoded_reviews.append(encode_sentence(review))\n",
    "    labels.append((1.0, 0.0))\n",
    "review_inputs = torch.tensor(encoded_reviews)\n",
    "review_labels = torch.tensor(labels)\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, {max_words}\")\n",
    "print(f\"Num reviews: {len(review_inputs)} / {len(review_labels)}\")\n",
    "print(f\"Vocab sample: {list(vocab.items())[0:15]}\")\n",
    "print(f\"Vocab inv sample: {list(vocab_inv.items())[0:15]}\")\n",
    "print(review_inputs[0])\n",
    "print(review_labels[0])\n",
    "print(review_inputs[-1])\n",
    "print(review_labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21619/21619 [00:00<00:00, 415947.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21619 21619 15877\n",
      "torch.Size([21619, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "WORD2VEC = 'data/GoogleNews-vectors-negative300.bin'\n",
    "MAX_WORDLEN = 50\n",
    "WEIGHT_SIZE = 4\n",
    "EMBED_DIM = 300  # Embedding size\n",
    "\n",
    "\n",
    "def load_word2vec(vocab: dict[str, int]) -> torch.tensor:\n",
    "    # Could be improved matching distribution of word2vec\n",
    "    vocab_vec = numpy.random.uniform(-0.25, 0.25, (len(vocab), EMBED_DIM))\n",
    "    vocab_vec[PAD_IDX] = numpy.zeros(EMBED_DIM)\n",
    "    found: set[int] = set()\n",
    "    with open(WORD2VEC, 'rb') as fd:\n",
    "        line = fd.readline()\n",
    "        parts = line.decode('utf-8').split(' ')\n",
    "        words = int(parts[0])\n",
    "        word_size = int(parts[1])\n",
    "        if word_size != EMBED_DIM:\n",
    "            raise ValueError(f\"Unexpected word size {word_size} != {EMBED_DIM}\")\n",
    "        for i in tqdm(range(0, words)):\n",
    "            # Read the next word\n",
    "            s = b''\n",
    "            while True:\n",
    "                ch = fd.read(1)\n",
    "                if ch == b' ':\n",
    "                    break\n",
    "                if ch == b'':\n",
    "                    raise ValueError(\"Unexpected eof\")\n",
    "                if ch != b'\\n':\n",
    "                    s += ch\n",
    "                if len(s) > word_size:\n",
    "                    raise ValueError(f\"Word was too long {s}\")\n",
    "            weights = fd.read(word_size * WEIGHT_SIZE)\n",
    "            wd = numpy.frombuffer(weights, dtype=numpy.float32)\n",
    "            word = s.decode('utf-8').strip().lower()\n",
    "            # Only load words in the vocabulary\n",
    "            if (idx := vocab.get(word)) is not None:\n",
    "                if idx not in found:\n",
    "                    vocab_vec[idx] = wd\n",
    "                    found |= set({idx})\n",
    "\n",
    "    return torch.tensor(vocab_vec)\n",
    "\n",
    "\n",
    "w2v_model = models.KeyedVectors.load_word2vec_format(WORD2VEC, binary=True)\n",
    "\n",
    "\n",
    "def encode_word2vec(vocab: dict[str, int]) -> torch.tensor:\n",
    "    # Could be improved matching distribution of word2vec\n",
    "    vocab_vec = numpy.random.uniform(-0.25, 0.25, (len(vocab), EMBED_DIM))\n",
    "    vocab_vec[PAD_IDX] = numpy.zeros(EMBED_DIM)\n",
    "    found = 0\n",
    "    for word, idx in tqdm(vocab.items()):\n",
    "        if word in w2v_model:\n",
    "            vocab_vec[idx] = w2v_model[word]\n",
    "            found += 1\n",
    "    return torch.tensor(vocab_vec, dtype=torch.float64), found\n",
    "\n",
    "vocab2vec, found = encode_word2vec(vocab)\n",
    "print(len(vocab), len(vocab2vec), found)\n",
    "print(vocab2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([-0.1839,  0.1440,  0.0476, -0.0091,  0.1883, -0.1222,  0.0843, -0.0199,\n",
      "        -0.1804,  0.2110], dtype=torch.float64)\n",
      "tensor([ 0.0801,  0.1050,  0.0498,  0.0535, -0.0674, -0.1206,  0.0352, -0.1187,\n",
      "         0.0439,  0.0302], dtype=torch.float64)\n",
      "\n",
      "vocab['car']\n",
      "6514\n",
      "vocab2vec['car']\n",
      "6514\n",
      "tensor([ 0.1309,  0.0084,  0.0334, -0.0588,  0.0400, -0.1426,  0.0493, -0.1689,\n",
      "         0.2090,  0.1196], dtype=torch.float64)\n",
      "w2v_model['car']\n",
      "[ 0.13085938  0.00842285  0.03344727 -0.05883789  0.04003906 -0.14257812\n",
      "  0.04931641 -0.16894531  0.20898438  0.11962891]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "print(vocab2vec[0][:10])\n",
    "print(vocab2vec[1][:10])\n",
    "print(vocab2vec[2][:10])\n",
    "print()\n",
    "print(\"vocab['car']\")\n",
    "print(vocab['car'])\n",
    "print(\"vocab2vec['car']\")\n",
    "print(vocab['car'])\n",
    "print(vocab2vec[6514][:10])\n",
    "print(\"w2v_model['car']\")\n",
    "print(w2v_model['car'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9595, 60]) torch.Size([9595, 2])\n",
      "torch.Size([1067, 60]) torch.Size([1067, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr, Xdev, Ytr, Ydev = train_test_split(review_inputs, review_labels, test_size=0.1, random_state=31337)\n",
    "\n",
    "print(Xtr.shape, Ytr.shape)\n",
    "print(Xdev.shape, Ydev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "FILTER_WINDOWS = (3, 4, 5)\n",
    "FEATURE_MAPS = 200\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"A model for training a CNN text classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddings: torch.tensor, rand_embed: bool, freeze_embedding: bool, num_classes: int, dropout: float = 0.5):\n",
    "        \"\"\"Initialize Model.\"\"\"\n",
    "        super().__init__()\n",
    "        if not rand_embed:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=freeze_embedding).float()\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=vocab2vec.shape[0],\n",
    "                embedding_dim=vocab2vec.shape[1],\n",
    "                padding_idx=0,\n",
    "                max_norm=5.0\n",
    "            )\n",
    "        self.conv_list = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=EMBED_DIM,\n",
    "                out_channels=FEATURE_MAPS,\n",
    "                kernel_size=filter_size,\n",
    "            )\n",
    "            for filter_size in FILTER_WINDOWS\n",
    "        ])\n",
    "        self.fc = nn.Linear(FEATURE_MAPS * len(FILTER_WINDOWS), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Out: (BATCH_SZ, MAX_SENTENCE_LEN, WORD_SIZE)\n",
    "        self.x_embed = self.embedding(x)\n",
    "        # Reshape to match conv1d input\n",
    "        # Out: (BATCH_SZ, WORD_SIZE, MAX_SENTENCE_LEN)\n",
    "        self.x_reshape = self.x_embed.permute(0, 2, 1) \n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-2)\n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-3)\n",
    "        # (BATCH_SZ, FEATURE_MAPS, MAX_SENTENCE_LEN-4)\n",
    "        self.x_conv_list = [F.relu(conv(self.x_reshape)) for conv in self.conv_list]\n",
    "        # (BATCH_SZ, FEATURE_MAPS, 1)\n",
    "        self.x_pool_list = [\n",
    "            F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in self.x_conv_list\n",
    "        ]\n",
    "        # (BATCH_SZ, FEATURE_MAPS * 3)\n",
    "        self.x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in self.x_pool_list], dim=1)\n",
    "        # (BATCH_SZ, FEATURE_MAPS * 3)\n",
    "        self.logits = self.fc(self.dropout(self.x_fc))\n",
    "        self.logits_class = F.softmax(self.logits, dim=1)\n",
    "        return self.logits_class\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  | 35.49i/s | 0.687 | 0.680 | 64.88 |  2.11   /  0.05  \n",
      " 1  | 39.67i/s | 0.664 | 0.655 | 65.92 |  1.89   /  0.05  \n",
      " 2  | 40.21i/s | 0.626 | 0.604 | 73.29 |  1.87   /  0.05  \n",
      " 3  | 40.31i/s | 0.587 | 0.563 | 76.23 |  1.86   /  0.05  \n",
      " 4  | 40.29i/s | 0.556 | 0.541 | 77.71 |  1.86   /  0.05  \n",
      " 5  | 40.44i/s | 0.534 | 0.528 | 78.40 |  1.85   /  0.05  \n",
      " 6  | 39.31i/s | 0.519 | 0.522 | 78.92 |  1.91   /  0.05  \n",
      " 7  | 40.24i/s | 0.505 | 0.513 | 79.27 |  1.86   /  0.05  \n",
      " 8  | 40.18i/s | 0.493 | 0.509 | 79.79 |  1.87   /  0.05  \n",
      " 9  | 40.34i/s | 0.480 | 0.506 | 80.31 |  1.86   /  0.05  \n",
      "10  | 40.18i/s | 0.471 | 0.503 | 79.71 |  1.87   /  0.05  \n",
      "11  | 40.33i/s | 0.461 | 0.502 | 79.88 |  1.86   /  0.05  \n",
      "12  | 40.16i/s | 0.452 | 0.501 | 80.57 |  1.87   /  0.05  \n",
      "13  | 40.39i/s | 0.444 | 0.501 | 80.05 |  1.86   /  0.05  \n",
      "14  | 40.31i/s | 0.433 | 0.498 | 79.97 |  1.86   /  0.05  \n",
      "15  | 40.16i/s | 0.427 | 0.498 | 80.31 |  1.87   /  0.05  \n",
      "16  | 39.08i/s | 0.418 | 0.497 | 80.40 |  1.92   /  0.05  \n",
      "17  | 40.38i/s | 0.410 | 0.498 | 79.97 |  1.86   /  0.05  \n",
      "18  | 40.38i/s | 0.406 | 0.495 | 80.14 |  1.86   /  0.05  \n",
      "19  | 40.37i/s | 0.397 | 0.494 | 80.83 |  1.86   /  0.05  \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "\n",
    "MINI_BATCH_SZ = 128\n",
    "\n",
    "g = torch.Generator(device=device).manual_seed(31337)\n",
    "g_cpu = torch.Generator().manual_seed(31337)\n",
    "\n",
    "\n",
    "tr_data = TensorDataset(Xtr, Ytr)\n",
    "tr_loader = DataLoader(tr_data, sampler=RandomSampler(tr_data, generator=g_cpu), batch_size=MINI_BATCH_SZ, pin_memory=True, pin_memory_device=device.type)\n",
    "\n",
    "val_data = TensorDataset(Xdev, Ydev)\n",
    "val_loader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=MINI_BATCH_SZ, pin_memory=True, pin_memory_device=device.type)\n",
    "\n",
    "model = Model(embeddings=vocab2vec, rand_embed=False, freeze_embedding=False, num_classes=2, dropout=0.5)\n",
    "\n",
    "lr = 0.25\n",
    "opt = torch.optim.Adadelta(model.parameters(), lr=lr, rho=0.95)\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    lossi = []\n",
    "    accuracyi = []\n",
    "    t0_epoch = time.time()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for step, batch in enumerate(tr_loader):\n",
    "            Xb, Yb = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "            logits = model.forward(Xb)\n",
    "            loss = F.cross_entropy(logits, Yb)\n",
    "            loss.backward()\n",
    "\n",
    "            lossi.append(loss.item())\n",
    "            accuracy = (torch.round(logits) == Yb).cpu().numpy().mean() * 100\n",
    "            accuracyi.append(accuracy)\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "    avg_train_loss = numpy.mean(lossi)\n",
    "    iters = len(lossi)\n",
    "    time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "    t0_epoch = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lossi = []\n",
    "        accuracyi = []\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            Xb, Yb = tuple(t.to(device) for t in batch)\n",
    "            logits = model.forward(Xb)\n",
    "            loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "            lossi.append(loss.item())\n",
    "            accuracy = (torch.round(logits) == Yb).cpu().numpy().mean() * 100\n",
    "            accuracyi.append(accuracy)\n",
    "\n",
    "        avg_eval_loss = numpy.mean(lossi)\n",
    "        avg_eval_accuracy = numpy.mean(accuracyi)\n",
    "\n",
    "    eval_time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "    print(f\"{epoch:^3} | {iters/time_elapsed:3.2f}i/s | {avg_train_loss:0.3f} | {avg_eval_loss:0.3f} | {avg_eval_accuracy:0.2f} | {time_elapsed:^7.2f} / {eval_time_elapsed:^7.2f}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This review is 69.52% positive.\n",
      "This review is 73.19% positive.\n",
      "This review is 98.76% positive.\n",
      "This review is 9.61% positive.\n",
      "This review is 54.91% positive.\n",
      "---\n",
      "This review is 0.01% positive.\n",
      "This review is 9.06% positive.\n",
      "This review is 0.42% positive.\n",
      "This review is 4.02% positive.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "def predict(text: str) -> None:\n",
    "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
    "    text = text.replace(\",\", \" ,\")\n",
    "    text = text.replace(\".\", \" .\").lower()\n",
    "    #print(text)\n",
    "    encoded = torch.tensor(encode_sentence(text), device=device)\n",
    "    input_data = encoded.unsqueeze(dim=0)\n",
    "\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(input_data)\n",
    "\n",
    "    # Compute probability\n",
    "    prob = logits.squeeze(dim=0)\n",
    "    print(f\"This review is {prob[1] * 100:.2f}% positive.\")\n",
    "\n",
    "\n",
    "predict(\"All of friends slept while watching this movie, but I really enjoyed it.\")\n",
    "predict(\"I have waited so long for this movie and I am now so satisfied and happy.\")\n",
    "predict(\"This is a great movie.\")\n",
    "predict(\"I was laughing the whole time.\")\n",
    "predict(\"Fantastic movie that I would watch again.\")\n",
    "print(\"---\")\n",
    "predict(\"This movie is long and boring.\")\n",
    "predict(\"I don't like the ending.\")\n",
    "predict(\"Do not bother watching this movie.\")\n",
    "predict(\"I hated this movie more than any other movie.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
